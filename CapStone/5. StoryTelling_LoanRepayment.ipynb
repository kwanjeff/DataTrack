{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0eb08d0",
   "metadata": {},
   "source": [
    "# StoryTelling - Predict likelyness of Client default on Loans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737001c5",
   "metadata": {},
   "source": [
    "copy start problem statement, where you got data \n",
    "\n",
    "data wrangling\n",
    "eda\n",
    "preprocess\n",
    "modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d3e1ed",
   "metadata": {},
   "source": [
    "issue with data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42197a",
   "metadata": {},
   "source": [
    "charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ecc7d",
   "metadata": {},
   "source": [
    "add  hypothesis test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889212d",
   "metadata": {},
   "source": [
    "details from model exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6c8bd",
   "metadata": {},
   "source": [
    "As a bank I want to rate a customer based on each client's attributes.  We want to create our own predictive analysis model that tells me the likelihood that this customer will default on oneâ€™s credit card loan or will fully repay the loan.\n",
    "\n",
    "Criteria for success: \n",
    "If we are able to identify top 10-12 categories which leads to customer defalutness.  With the categories identified, am I able to accurately predict 85% clients that are flagged as likely to default.  Next step is what number of categories that can change prediction from 85% to 95% of flagged clients will default on loan.  If a lower amount of loan was given will it decrease the rate of default.\n",
    "\n",
    "\n",
    "The dataset used for this submission is found at https://www.kaggle.com/mishra5001/credit-card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25067cf0",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4c0fb",
   "metadata": {},
   "source": [
    "The dataset found on kaggle was not large but the columns of features were quite extensive.  The first task I took was rename 2 columns.  Most of the columns were selfexplanitory or gave you a glimpse of what the data was about.  \n",
    "\n",
    "I had to dorp a lot of these features(columns) were dropped because the data was too sparse or unecessary.  This dataset had 122 features.  An exammple is that the following columns had 60% of data null.  In Task 2.3 I create a threshold of of 40% that mad missing data and they were automatically droppped.  \n",
    "\n",
    "In Task 2.2 there were exception where the data was missing but it could been explain that the car was new so instead of 1 year they left it blank.  The columnn that had that was 'OWN_CAR_AGE'.  Now the columns that we are keeping no longer have null values\n",
    "\n",
    "After dropping the columns that seem unneeded we were down to 76 columns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc01ad",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c899c72",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b1158f3",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f002d29",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a75ebf64",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611c408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
